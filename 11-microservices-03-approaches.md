# Домашнее задание к занятию «Микросервисы: подходы». Наталия Ханова. 

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

Выбранным критериям соответствует GitLab - популярный веб-инструмент жизненного цикла DevOps с открытым исходным кодом, представляющий систему управления Git-репозиториями. GitLab предоставляет пользователям не только удобный интерфейс для работы с кодом, но и возможности автоматизации сборки, тестирования и развертывания программного обеспечения с помощью инструмента GitLab CI/CD.
Правила для автоматической сборки, тестирования и деплоя приложения при каждом изменении кода задаются в файле конфигурации .gitlab-ci.yml. Посредством этого файла можно привязать настройки к каждой сборке, задать условия и параметры запуска, а также определить кастомные шаги. С помощью .gitlab-ci.yml и связанных YAML-файлов возможно создавать шаблоны для различных конфигураций и организовывать параллельный запуск разных сборок и тестов.
Агенты GitLab Runners, выполняющие задачи пайплайна, могут быть расположены как в облаке, так и на собственных серверах. Также раннеры могут работать в Docker-режиме, обеспечивая изоляцию и удобство настройки.
Секретные данные в GitLab задаются через переменные окружения (CI/CD Variables), которые хранятся в настройках проекта или группы. Важно, что секреты не должны храниться в незашифрованном виде в репозитории или выводиться в логах, а доступ к настройкам должен быть ограничен правами доступа.
В качестве специализированного решения для управления секретами можно использовать HashiCorp Vault, который предоставляет продвинутый контроль доступа и возможность динамической генерации секретов. Хотя Vault требует дополнительной настройки и развертывания, для крупных проектов с микросервисной архитектурой оно обеспечивает более высокий уровень безопасности по сравнению с использованием переменных окружения.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

Удобным и проверенным решением для сбора и анализа логов в условиях микросервисной архитектуры является Elastic Stack (ранее ELK Stack). Его основными компонентами являются:

* Elasticsearch — распределённая база данных, оптимизированная для полнотекстового поиска. Обеспечивает быструю индексацию, репликацию и масштабирование данных, отлично подходит для хранения и анализа логов большого объёма.
* Logstash — инструмент для приёма, парсинга (опционально) и передачи логов в Elasticsearch. Может быть настроен на получение логов как из stdout (стандартного потока вывода приложений), так и из файлов логов. Поддерживает буферизацию и повторную отправку данных (ретраи), что обеспечивает гарантированную доставку логов.
* Kibana — веб-интерфейс для визуализации и анализа логов. Предоставляет удобный поиск, фильтрацию, сортировку записей, создание дашбордов и графиков. Kibana также позволяет сохранять поисковые запросы и делиться ссылками на них с другими разработчиками.

Дополнительно может использоваться Filebeat - лёгкий и ресурсоэффективный агент для сбора логов с хостов. Filebeat устанавливается на каждый сервер, считывает логи из stdout или лог-файлов и пересылает их либо напрямую в Elasticsearch, либо в Logstash для обработки и структурирования перед сохранением в Elasticsearch. Filebeat потребляет значительно меньше ресурсов, чем Logstash, и лучше подходит для масштабируемых систем с большим числом микросервисов.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

Подходящим решением для мониторинга хостов и сервисов и удобной визуализации данных станет связка Prometheus и Grafana.

Exporters, агенты для сбора метрик с хостов, входят в состав стека Prometheus, и с их помощью можно настроить сбор данных с каждого сервера. Например, с помощью агента node_exporter настраивается сбор метрик состояния ресурсов хоста (CPU, RAM, HDD, Network).
Для сбора метрик потребления ресурсов каждым сервисом могут использоваться агент cAdvisor (если сервисы запущены в контейнерах), агент process_exporter (если сервисы работают напрямую на хостах), а также клиентские библиотеки Prometheus, которые позволяют сервисам самостоятельно экспортировать специфичные метрики.
Для анализа метрик в Prometheus применяется язык запросов PromQL (Prometheus Query Language), позволяющий фильтровать, агрегировать и комбинировать метрики, а также настраивать сложные правила алертов. Это удобный и мощный инструмент для глубокого анализа данных.

Grafana, используя Prometheus в качестве источника данных, предоставляет пользователю удобный веб-интерфейс для визуализации информации, настройки гибких дашбордов и панелей мониторинга, включая сравнение метрик разных сервисов. Также Grafana поддерживает настройку уведомлений, что помогает своевременно реагировать на события, влияющие на надежность и стабильность работы системы.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
